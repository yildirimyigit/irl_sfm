{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=6, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=1024, bias=True)\n",
      "  (fc4): Linear(in_features=1024, out_features=800, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(6, 256)\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.fc3 = nn.Linear(512, 1024)\n",
    "        self.fc4 = nn.Linear(1024, 800)  # 800 = 400*2 (400 points, 2d)\n",
    "\n",
    "    def forward(self, x):  # x are the states: [d_obs_x, d_obs_y, d_goal_x, d_goal_y]\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5267/5267 [00:15<00:00, 335.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5266\n",
      "5266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "data_root_path = '/home/yigit/Documents/projects/irl_sfm/data/demonstrations/sfm/continuous_poses_1/new/combined/'\n",
    "\n",
    "num_traj = 0\n",
    "x_list, y_list = [], []\n",
    "\n",
    "for filename in tqdm(os.listdir(data_root_path)):\n",
    "    if filename.endswith(\".npy\"):\n",
    "        filepath = os.path.join(data_root_path, filename)\n",
    "        config = filename.strip('.npy').split('_')  # format: <sx>_<gx>_<ox>_<oy>.npy\n",
    "        sx, sy = float(config[0]), 0.0\n",
    "        gx, gy = float(config[1]), 13.0\n",
    "        ox, oy = float(config[2]), float(config[3])\n",
    "        \n",
    "        x_list.append([sx, sy, gx, gy, ox, oy])\n",
    "        trajectory = np.load(filepath, allow_pickle=True, encoding='latin1')\n",
    "        desired_len = 400\n",
    "        indices = np.linspace(0, len(trajectory)-1, desired_len, dtype=int)\n",
    "        y_list.append(trajectory[indices, -3:-1].tolist())\n",
    "\n",
    "print(len(x_list))\n",
    "print(len(y_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5266, 800])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "num_instances_train = len(x_list)\n",
    "\n",
    "x_train = torch.Tensor(x_list)\n",
    "y_train = torch.Tensor(y_list).view(num_instances_train, desired_len*2)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yigit/.local/lib/python3.7/site-packages/torch/autograd/__init__.py:132: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  allow_unreachable=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,    50] loss: 1.000\n",
      "[20,    50] loss: 0.290\n",
      "[30,    50] loss: 0.205\n",
      "[40,    50] loss: 0.204\n",
      "[50,    50] loss: 0.202\n",
      "[60,    50] loss: 0.198\n",
      "[70,    50] loss: 0.194\n",
      "[80,    50] loss: 0.193\n",
      "[90,    50] loss: 0.193\n",
      "[100,    50] loss: 0.191\n",
      "[110,    50] loss: 0.190\n",
      "[120,    50] loss: 0.188\n",
      "[130,    50] loss: 0.189\n",
      "[140,    50] loss: 0.188\n",
      "[150,    50] loss: 0.187\n",
      "[160,    50] loss: 0.185\n",
      "[170,    50] loss: 0.184\n",
      "[180,    50] loss: 0.182\n",
      "[190,    50] loss: 0.182\n",
      "[200,    50] loss: 0.182\n",
      "[210,    50] loss: 0.181\n",
      "[220,    50] loss: 0.180\n",
      "[230,    50] loss: 0.180\n",
      "[240,    50] loss: 0.179\n",
      "[250,    50] loss: 0.178\n",
      "[260,    50] loss: 0.177\n",
      "[270,    50] loss: 0.175\n",
      "[280,    50] loss: 0.175\n",
      "[290,    50] loss: 0.175\n",
      "[300,    50] loss: 0.173\n",
      "[310,    50] loss: 0.170\n",
      "[320,    50] loss: 0.171\n",
      "[330,    50] loss: 0.169\n",
      "[340,    50] loss: 0.168\n",
      "[350,    50] loss: 0.166\n",
      "[360,    50] loss: 0.165\n",
      "[370,    50] loss: 0.164\n",
      "[380,    50] loss: 0.165\n",
      "[390,    50] loss: 0.160\n",
      "[400,    50] loss: 0.160\n",
      "[410,    50] loss: 0.159\n",
      "[420,    50] loss: 0.159\n",
      "[430,    50] loss: 0.159\n",
      "[440,    50] loss: 0.157\n",
      "[450,    50] loss: 0.157\n",
      "[460,    50] loss: 0.155\n",
      "[470,    50] loss: 0.153\n",
      "[480,    50] loss: 0.153\n",
      "[490,    50] loss: 0.152\n",
      "[500,    50] loss: 0.151\n",
      "[510,    50] loss: 0.147\n",
      "[520,    50] loss: 0.148\n",
      "[530,    50] loss: 0.146\n",
      "[540,    50] loss: 0.145\n",
      "[550,    50] loss: 0.144\n",
      "[560,    50] loss: 0.145\n",
      "[570,    50] loss: 0.143\n",
      "[580,    50] loss: 0.141\n",
      "[590,    50] loss: 0.139\n",
      "[600,    50] loss: 0.140\n",
      "[610,    50] loss: 0.136\n",
      "[620,    50] loss: 0.137\n",
      "[630,    50] loss: 0.135\n",
      "[640,    50] loss: 0.133\n",
      "[650,    50] loss: 0.134\n",
      "[660,    50] loss: 0.128\n",
      "[670,    50] loss: 0.130\n",
      "[680,    50] loss: 0.128\n",
      "[690,    50] loss: 0.124\n",
      "[700,    50] loss: 0.124\n",
      "[710,    50] loss: 0.124\n",
      "[720,    50] loss: 0.124\n",
      "[730,    50] loss: 0.122\n",
      "[740,    50] loss: 0.121\n",
      "[750,    50] loss: 0.119\n",
      "[760,    50] loss: 0.117\n",
      "[770,    50] loss: 0.117\n",
      "[780,    50] loss: 0.115\n",
      "[790,    50] loss: 0.113\n",
      "[800,    50] loss: 0.112\n",
      "[810,    50] loss: 0.109\n",
      "[820,    50] loss: 0.111\n",
      "[830,    50] loss: 0.109\n",
      "[840,    50] loss: 0.108\n",
      "[850,    50] loss: 0.106\n",
      "[860,    50] loss: 0.103\n",
      "[870,    50] loss: 0.104\n",
      "[880,    50] loss: 0.101\n",
      "[890,    50] loss: 0.100\n",
      "[900,    50] loss: 0.100\n",
      "[910,    50] loss: 0.097\n",
      "[920,    50] loss: 0.096\n",
      "[930,    50] loss: 0.096\n",
      "[940,    50] loss: 0.094\n",
      "[950,    50] loss: 0.093\n",
      "[960,    50] loss: 0.092\n",
      "[970,    50] loss: 0.090\n",
      "[980,    50] loss: 0.090\n",
      "[990,    50] loss: 0.087\n",
      "[1000,    50] loss: 0.086\n",
      "[1010,    50] loss: 0.085\n",
      "[1020,    50] loss: 0.084\n",
      "[1030,    50] loss: 0.083\n",
      "[1040,    50] loss: 0.082\n",
      "[1050,    50] loss: 0.082\n",
      "[1060,    50] loss: 0.080\n",
      "[1070,    50] loss: 0.077\n",
      "[1080,    50] loss: 0.077\n",
      "[1090,    50] loss: 0.076\n",
      "[1100,    50] loss: 0.075\n",
      "[1110,    50] loss: 0.074\n",
      "[1120,    50] loss: 0.074\n",
      "[1130,    50] loss: 0.073\n",
      "[1140,    50] loss: 0.072\n",
      "[1150,    50] loss: 0.072\n",
      "[1160,    50] loss: 0.071\n",
      "[1170,    50] loss: 0.070\n",
      "[1180,    50] loss: 0.069\n",
      "[1190,    50] loss: 0.068\n",
      "[1200,    50] loss: 0.067\n",
      "[1210,    50] loss: 0.066\n",
      "[1220,    50] loss: 0.065\n",
      "[1230,    50] loss: 0.064\n",
      "[1240,    50] loss: 0.065\n",
      "[1250,    50] loss: 0.062\n",
      "[1260,    50] loss: 0.064\n",
      "[1270,    50] loss: 0.062\n",
      "[1280,    50] loss: 0.060\n",
      "[1290,    50] loss: 0.060\n",
      "[1300,    50] loss: 0.060\n",
      "[1310,    50] loss: 0.060\n",
      "[1320,    50] loss: 0.059\n",
      "[1330,    50] loss: 0.059\n",
      "[1340,    50] loss: 0.058\n",
      "[1350,    50] loss: 0.057\n",
      "[1360,    50] loss: 0.057\n",
      "[1370,    50] loss: 0.055\n",
      "[1380,    50] loss: 0.057\n",
      "[1390,    50] loss: 0.055\n",
      "[1400,    50] loss: 0.054\n",
      "[1410,    50] loss: 0.055\n",
      "[1420,    50] loss: 0.053\n",
      "[1430,    50] loss: 0.053\n",
      "[1440,    50] loss: 0.051\n",
      "[1450,    50] loss: 0.051\n",
      "[1460,    50] loss: 0.052\n",
      "[1470,    50] loss: 0.052\n",
      "[1480,    50] loss: 0.051\n",
      "[1490,    50] loss: 0.050\n",
      "[1500,    50] loss: 0.051\n",
      "[1510,    50] loss: 0.051\n",
      "[1520,    50] loss: 0.049\n",
      "[1530,    50] loss: 0.048\n",
      "[1540,    50] loss: 0.048\n",
      "[1550,    50] loss: 0.048\n",
      "[1560,    50] loss: 0.048\n",
      "[1570,    50] loss: 0.046\n",
      "[1580,    50] loss: 0.047\n",
      "[1590,    50] loss: 0.047\n",
      "[1600,    50] loss: 0.046\n",
      "[1610,    50] loss: 0.045\n",
      "[1620,    50] loss: 0.045\n",
      "[1630,    50] loss: 0.045\n",
      "[1640,    50] loss: 0.044\n",
      "[1650,    50] loss: 0.044\n",
      "[1660,    50] loss: 0.044\n",
      "[1670,    50] loss: 0.043\n",
      "[1680,    50] loss: 0.043\n",
      "[1690,    50] loss: 0.043\n",
      "[1700,    50] loss: 0.043\n",
      "[1710,    50] loss: 0.042\n",
      "[1720,    50] loss: 0.042\n",
      "[1730,    50] loss: 0.042\n",
      "[1740,    50] loss: 0.041\n",
      "[1750,    50] loss: 0.042\n",
      "[1760,    50] loss: 0.041\n",
      "[1770,    50] loss: 0.041\n",
      "[1780,    50] loss: 0.040\n",
      "[1790,    50] loss: 0.040\n",
      "[1800,    50] loss: 0.040\n",
      "[1810,    50] loss: 0.039\n",
      "[1820,    50] loss: 0.040\n",
      "[1830,    50] loss: 0.039\n",
      "[1840,    50] loss: 0.039\n",
      "[1850,    50] loss: 0.038\n",
      "[1860,    50] loss: 0.038\n",
      "[1870,    50] loss: 0.038\n",
      "[1880,    50] loss: 0.038\n",
      "[1890,    50] loss: 0.038\n",
      "[1900,    50] loss: 0.038\n",
      "[1910,    50] loss: 0.036\n",
      "[1920,    50] loss: 0.037\n",
      "[1930,    50] loss: 0.037\n",
      "[1940,    50] loss: 0.036\n",
      "[1950,    50] loss: 0.036\n",
      "[1960,    50] loss: 0.036\n",
      "[1970,    50] loss: 0.035\n",
      "[1980,    50] loss: 0.036\n",
      "[1990,    50] loss: 0.035\n",
      "[2000,    50] loss: 0.035\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "epochs = 2000\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset <epochs> times\n",
    "\n",
    "    train_ids = torch.randperm(num_instances_train)  # shuffle instances every epoch\n",
    "    num_iters = int(num_instances_train/batch_size)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i in range(num_iters):\n",
    "        batch_train_ids = train_ids[i*batch_size:(i+1)*batch_size]\n",
    "        \n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = x_train[batch_train_ids, :]\n",
    "        labels = y_train[batch_train_ids, :]\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:    # print every 50 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 50), end = \"\\r\")\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print()\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the trained model\n",
    "model_root_path = f'/home/yigit/Documents/projects/irl_sfm/python_ws/nn_baseline_for_cnmp/model/nn_models/'\n",
    "torch.save(net.state_dict(), f'{model_root_path}model_traj_est_state_dict_new_combined.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
